{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary packages\n",
    "import time;\n",
    "import numpy as np; \n",
    "import matplotlib.pyplot as plt; \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import python.data as datameta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Initialisations\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datameta.processData('data/clean_data.csv'); \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into x and y\n",
    "x_keys = [\n",
    "    \"Time (h)\", \"Aeration rate(Fg:L/h)\", \"Sugar feed rate(Fs:L/h)\",\"Acid flow rate(Fa:L/h)\",\n",
    "    \"Base flow rate(Fb:L/h)\",\"Heating/cooling water flow rate(Fc:L/h)\",\"Heating water flow rate(Fh:L/h)\",\n",
    "    \"Water for injection/dilution(Fw:L/h)\",\"Substrate concentration(S:g/L)\",\"PAA flow(Fpaa:PAA flow (L/h))\",\n",
    "    \"Oil flow(Foil:L/hr)\", \"Oxygen Uptake Rate(OUR:(g min^{-1}))\", \"Ammonia shots(NH3_shots:kgs)\",\n",
    "    # Converted variables\n",
    "    \"0 - Recipe driven 1 - Operator controlled(Control_ref:Control ref)\",\n",
    "    \"Air head pressure(pressure:bar)\", \"Temperature(T:K)\", \"pH(pH:pH)\", \"Vessel Volume(V:L)\"\n",
    "]\n",
    "(x,y) = datameta.xy_split(data,x_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = round(time.time() * 1000) % 100; \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.9, random_state=rand)\n",
    "\n",
    "print (\"x_train: \", x_train.shape)\n",
    "print (\"x_test: \", x_test.shape)\n",
    "\n",
    "print (\"y_train: \", y_train.shape)\n",
    "print (\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to torch tensors\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.from_numpy(x.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "        self.len = self.x.shape[0]\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "   \n",
    "batch_size = 32\n",
    "\n",
    "# Instantiate training and test data\n",
    "train_data = Data(x_train.to_numpy(), y_train.to_numpy())\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = Data(x_test.to_numpy(), y_test.to_numpy())\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just checking if it worked\n",
    "for batch, (x, y) in enumerate(train_dataloader):\n",
    "    print(f\"Batch: {batch+1}\")\n",
    "    print(f\"X shape: {x.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(x_keys)\n",
    "hidden_dim = 950\n",
    "output_dim = len(y_keys)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        nn.init.kaiming_uniform_(self.layer_1.weight, nonlinearity=\"relu\")\n",
    "        self.layer_2 = nn.Linear(hidden_dim, output_dim)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.layer_1(x))\n",
    "        x = self.layer_2(x)\n",
    "\n",
    "        return x\n",
    "       \n",
    "model = NeuralNetwork(input_dim, hidden_dim, output_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1500\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x, y in train_dataloader:\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        # forward + backward + optimize\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss_values.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "\n",
    "# plt.plot(loss_values[500:])\n",
    "plt.plot(loss_values)\n",
    "print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0.0\n",
    "correct = 0.0\n",
    "y_pred = []\n",
    "\n",
    "def isClose(base, known, tol):\n",
    "    return np.abs((base - known) / base) <= tol\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_dataloader:\n",
    "        outputs = model(x)\n",
    "        np.append(y_pred, outputs)\n",
    "        np.append(y_test, y)\n",
    "        # y_pred.append(predicted)\n",
    "        # y_test.append(y)\n",
    "        total += y.size(0)\n",
    "        correct += np.sum(isClose(outputs.numpy(), y.numpy(), tol=0.1))\n",
    "\n",
    "print(f'Accuracy out of {total} test instances: {(100 * correct) / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
